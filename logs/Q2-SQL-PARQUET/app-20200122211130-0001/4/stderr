Spark Executor Command: "/usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java" "-cp" "/home/user/spark-2.4.4-bin-hadoop2.7/conf/:/home/user/spark-2.4.4-bin-hadoop2.7/jars/*" "-Xmx512M" "-Dspark.driver.port=46806" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@master:46806" "--executor-id" "4" "--hostname" "192.168.0.2" "--cores" "1" "--app-id" "app-20200122211130-0001" "--worker-url" "spark://Worker@192.168.0.2:41553"
========================================

Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
20/01/22 21:17:25 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 3590@slave
20/01/22 21:17:25 INFO SignalUtils: Registered signal handler for TERM
20/01/22 21:17:25 INFO SignalUtils: Registered signal handler for HUP
20/01/22 21:17:25 INFO SignalUtils: Registered signal handler for INT
20/01/22 21:17:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
20/01/22 21:17:27 INFO SecurityManager: Changing view acls to: user
20/01/22 21:17:27 INFO SecurityManager: Changing modify acls to: user
20/01/22 21:17:27 INFO SecurityManager: Changing view acls groups to: 
20/01/22 21:17:27 INFO SecurityManager: Changing modify acls groups to: 
20/01/22 21:17:27 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(user); groups with view permissions: Set(); users  with modify permissions: Set(user); groups with modify permissions: Set()
20/01/22 21:17:28 INFO TransportClientFactory: Successfully created connection to master/192.168.0.1:46806 after 182 ms (0 ms spent in bootstraps)
20/01/22 21:17:28 INFO SecurityManager: Changing view acls to: user
20/01/22 21:17:28 INFO SecurityManager: Changing modify acls to: user
20/01/22 21:17:28 INFO SecurityManager: Changing view acls groups to: 
20/01/22 21:17:28 INFO SecurityManager: Changing modify acls groups to: 
20/01/22 21:17:28 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(user); groups with view permissions: Set(); users  with modify permissions: Set(user); groups with modify permissions: Set()
20/01/22 21:17:28 INFO TransportClientFactory: Successfully created connection to master/192.168.0.1:46806 after 6 ms (0 ms spent in bootstraps)
20/01/22 21:17:28 INFO DiskBlockManager: Created local directory at /tmp/spark-7012dd7e-2a36-4811-a74e-2fcdd733c44d/executor-28f3e50d-35ff-44ee-a818-479766a666f6/blockmgr-55fed6c3-8710-4895-8064-145a3b89df7f
20/01/22 21:17:28 INFO MemoryStore: MemoryStore started with capacity 93.3 MB
20/01/22 21:17:29 INFO WorkerWatcher: Connecting to worker spark://Worker@192.168.0.2:41553
20/01/22 21:17:29 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@master:46806
20/01/22 21:17:29 INFO TransportClientFactory: Successfully created connection to /192.168.0.2:41553 after 42 ms (0 ms spent in bootstraps)
20/01/22 21:17:29 INFO WorkerWatcher: Successfully connected to spark://Worker@192.168.0.2:41553
20/01/22 21:17:29 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
20/01/22 21:17:29 INFO Executor: Starting executor ID 4 on host 192.168.0.2
20/01/22 21:17:29 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37104.
20/01/22 21:17:29 INFO NettyBlockTransferService: Server created on 192.168.0.2:37104
20/01/22 21:17:29 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/01/22 21:17:29 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(4, 192.168.0.2, 37104, None)
20/01/22 21:17:29 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(4, 192.168.0.2, 37104, None)
20/01/22 21:17:29 INFO BlockManager: Initialized BlockManager: BlockManagerId(4, 192.168.0.2, 37104, None)
20/01/22 21:17:29 INFO CoarseGrainedExecutorBackend: Got assigned task 418
20/01/22 21:17:29 INFO Executor: Running task 0.2 in stage 11.0 (TID 418)
20/01/22 21:17:29 INFO MapOutputTrackerWorker: Updating epoch to 4 and clearing cache
20/01/22 21:17:29 INFO TorrentBroadcast: Started reading broadcast variable 12
20/01/22 21:17:30 INFO TransportClientFactory: Successfully created connection to master/192.168.0.1:43984 after 14 ms (0 ms spent in bootstraps)
20/01/22 21:17:30 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 11.7 KB, free 93.3 MB)
20/01/22 21:17:30 INFO TorrentBroadcast: Reading broadcast variable 12 took 180 ms
20/01/22 21:17:30 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 26.2 KB, free 93.3 MB)
20/01/22 21:17:32 INFO CodeGenerator: Code generated in 522.359657 ms
20/01/22 21:17:32 INFO CodeGenerator: Code generated in 136.603124 ms
20/01/22 21:17:32 INFO CodeGenerator: Code generated in 58.267808 ms
20/01/22 21:17:33 INFO FileScanRDD: Reading File path: hdfs://master:9000/yellow_tripdata_1m.parquet/part-00001-359368f2-e1ed-40ea-a55e-415129271431-c000.snappy.parquet, range: 0-28756588, partition values: [empty row]
20/01/22 21:17:33 INFO TorrentBroadcast: Started reading broadcast variable 10
20/01/22 21:17:33 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 24.3 KB, free 93.2 MB)
20/01/22 21:17:33 INFO TorrentBroadcast: Reading broadcast variable 10 took 14 ms
20/01/22 21:17:33 INFO CodeGenerator: Code generated in 78.494082 ms
20/01/22 21:17:33 INFO CodeGenerator: Code generated in 49.670603 ms
20/01/22 21:17:33 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 331.8 KB, free 92.9 MB)
20/01/22 21:17:36 INFO FilterCompat: Filtering using predicate: noteq(StartDate, null)
20/01/22 21:17:36 INFO FilterCompat: Filtering using predicate: noteq(StartDate, null)
20/01/22 21:17:36 INFO FilterCompat: Filtering using predicate: noteq(StartDate, null)
20/01/22 21:17:36 INFO CodecPool: Got brand-new decompressor [.snappy]
20/01/22 21:17:50 INFO FileScanRDD: Reading File path: hdfs://master:9000/yellow_tripdata_1m.parquet/part-00002-359368f2-e1ed-40ea-a55e-415129271431-c000.snappy.parquet, range: 0-28677886, partition values: [empty row]
20/01/22 21:17:50 INFO FilterCompat: Filtering using predicate: noteq(StartDate, null)
20/01/22 21:17:50 INFO FilterCompat: Filtering using predicate: noteq(StartDate, null)
20/01/22 21:17:50 INFO FilterCompat: Filtering using predicate: noteq(StartDate, null)
20/01/22 21:17:54 INFO TaskMemoryManager: Memory used in task 418
20/01/22 21:17:54 INFO TaskMemoryManager: Acquired by HybridRowQueue(org.apache.spark.memory.TaskMemoryManager@a1e1bb5,/tmp/spark-7012dd7e-2a36-4811-a74e-2fcdd733c44d/executor-28f3e50d-35ff-44ee-a818-479766a666f6/spark-500fe83b-ef46-46e8-828f-ad65806656f6,7,org.apache.spark.serializer.SerializerManager@772ae0dd): 92.9 MB
20/01/22 21:17:54 INFO TaskMemoryManager: 0 bytes of memory were used by task 418 but are not associated with specific consumers
20/01/22 21:17:54 INFO TaskMemoryManager: 97428757 bytes of memory are used for execution and 403383 bytes of memory are used for storage
20/01/22 21:18:03 INFO FileScanRDD: Reading File path: hdfs://master:9000/yellow_tripdata_1m.parquet/part-00011-359368f2-e1ed-40ea-a55e-415129271431-c000.snappy.parquet, range: 0-28592467, partition values: [empty row]
20/01/22 21:18:03 INFO FilterCompat: Filtering using predicate: noteq(StartDate, null)
20/01/22 21:18:03 INFO FilterCompat: Filtering using predicate: noteq(StartDate, null)
20/01/22 21:18:03 INFO FilterCompat: Filtering using predicate: noteq(StartDate, null)
20/01/22 21:18:43 INFO FileScanRDD: Reading File path: hdfs://master:9000/yellow_tripdata_1m.parquet/part-00000-359368f2-e1ed-40ea-a55e-415129271431-c000.snappy.parquet, range: 0-28061867, partition values: [empty row]
20/01/22 21:18:43 INFO FilterCompat: Filtering using predicate: noteq(StartDate, null)
20/01/22 21:18:43 INFO FilterCompat: Filtering using predicate: noteq(StartDate, null)
20/01/22 21:18:43 INFO FilterCompat: Filtering using predicate: noteq(StartDate, null)
20/01/22 21:19:01 INFO PythonUDFRunner: Times: total = 86626, boot = 569, init = 4097, finish = 81960
20/01/22 21:19:01 INFO Executor: Finished task 0.2 in stage 11.0 (TID 418). 2475 bytes result sent to driver
20/01/22 21:19:01 INFO CoarseGrainedExecutorBackend: Got assigned task 419
20/01/22 21:19:01 INFO Executor: Running task 2.0 in stage 11.0 (TID 419)
20/01/22 21:19:01 INFO FileScanRDD: Reading File path: hdfs://master:9000/yellow_tripdata_1m.parquet/part-00012-359368f2-e1ed-40ea-a55e-415129271431-c000.snappy.parquet, range: 0-27168230, partition values: [empty row]
20/01/22 21:19:01 INFO FilterCompat: Filtering using predicate: noteq(StartDate, null)
20/01/22 21:19:01 INFO FilterCompat: Filtering using predicate: noteq(StartDate, null)
20/01/22 21:19:01 INFO FilterCompat: Filtering using predicate: noteq(StartDate, null)
20/01/22 21:19:17 INFO TaskMemoryManager: Memory used in task 419
20/01/22 21:19:17 INFO TaskMemoryManager: Acquired by HybridRowQueue(org.apache.spark.memory.TaskMemoryManager@5c675f77,/tmp/spark-7012dd7e-2a36-4811-a74e-2fcdd733c44d/executor-28f3e50d-35ff-44ee-a818-479766a666f6/spark-500fe83b-ef46-46e8-828f-ad65806656f6,7,org.apache.spark.serializer.SerializerManager@772ae0dd): 92.9 MB
20/01/22 21:19:17 INFO TaskMemoryManager: 0 bytes of memory were used by task 419 but are not associated with specific consumers
20/01/22 21:19:17 INFO TaskMemoryManager: 97428757 bytes of memory are used for execution and 403383 bytes of memory are used for storage
20/01/22 21:19:41 INFO FileScanRDD: Reading File path: hdfs://master:9000/yellow_tripdata_1m.parquet/part-00008-359368f2-e1ed-40ea-a55e-415129271431-c000.snappy.parquet, range: 0-26950106, partition values: [empty row]
20/01/22 21:19:41 INFO FilterCompat: Filtering using predicate: noteq(StartDate, null)
20/01/22 21:19:41 INFO FilterCompat: Filtering using predicate: noteq(StartDate, null)
20/01/22 21:19:41 INFO FilterCompat: Filtering using predicate: noteq(StartDate, null)
OpenJDK 64-Bit Server VM warning: INFO: os::commit_memory(0x00000000f1a00000, 22544384, 0) failed; error='Cannot allocate memory' (errno=12)
